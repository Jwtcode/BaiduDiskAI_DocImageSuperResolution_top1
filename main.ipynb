{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 百度网盘AI大赛-文档图片超分比赛第1名方案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、赛题分析\n",
    "此次大赛主题结合日常生活常见情景展开，大家平时在使用手机进行拍照、扫描的时候，往往会需要将图片放大的场景，可是分辨率放大，图片中的元素都变得模糊起来，进而难以使用。本次比赛希望选手们通过算法等知识技术，帮助人们将因为放大而模糊的图片复原，提高图片分辨率，实现文档图像的“无损放大”，让其重新发挥作用。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 数据分析\n",
    "- 本次比赛最新发布的数据集共包含训练集、A榜测试集、B榜测试集三个部分，其中训练集共3000个样本，A榜测试集共200个样本，B榜测试集共200个样本,抽取一部分数据如图：：\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a.jpg)\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a_0_000.jpg)\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a_0_000.png)\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、评价标准\n",
    "评价指标为 PSNR 和 MSSSIM；\n",
    "\n",
    "用于评价的机器环境仅提供两种框架模型运行环境：paddlepaddle 和 onnxruntime，其他框架模型可转换为\n",
    "上述两种框架的模型；\n",
    "\n",
    "机器配置：V100，显存32G，内存30G；\n",
    "\n",
    "单张图片耗时>5s，决赛中的性能分数记0分。\n",
    "\n",
    "由评价标准可知，不能使用大模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 三、模型设计\n",
    "\n",
    "- 针对图像超分这个任务，我们查阅了相关资料，传统的文本评价标准是以OCR模型识别的准确率来比较的，目的是提高文字识别准确率，但是此次百度网盘的文档超分比赛，评分的标准是PSNR与MS_SSIM，所以该任务属于重建优化的范畴，所以我们选择了基于卷积架构的rcan作为我们此次的baseline,相比于transformer架构的模型，卷积架构会更加稳定。本次比赛要产生原图放大2倍和放大4倍的结果，如果分开计算必然耗时严重，所以我们将两个任务合并。\n",
    "\n",
    "![](![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/pipeline.png)\n",
    "\n",
    "- 从网络结构图上可以直观的看出改进后rcan由单分支网络变成了双分支网络，一个分支负责产生放大2倍的结果，一个分支负责产生放大4倍的结果。原始的racn使用了均值漂移的聚类算法，考虑到本次训练数据集的像素值大部分只分布在0和255附近，便删去这一部分。\n",
    "\n",
    "- 训练数据集的内容分为中文图片和英文图片，考虑到语言之间的差异性以及语言文字的先验性，决定中英文分开训练，所以在测试的时候需要一个二分类模型来判断中文还是英文，我们使用精剪后的vgg来做二分类。\n",
    "\n",
    "![](![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/pipeline.png)\n",
    "\n",
    "- 由于分类任务非常容易，所以该网络只由几层卷积构成。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 四、数据处理与增强\n",
    "\n",
    "### 数据划分\n",
    "- 训练的文档的图像尺寸很大，而且四周存在很多纯色空白，为减小训练过程中的IO占用以及空白样本过于简单不利于模型收敛，应该将其裁剪掉四周的空白区域，在进行切块处理\n",
    "- 以步长64，大小为128进行切块\n",
    "\n",
    "### 数据筛选\n",
    "- 在进行切块处理后，仍然存在一些图像块是白色的，由于他们很容易恢复，对模型的收敛可能会产生负面的影响，导致收敛不充分\n",
    "- 我们通过计算图像梯度，并将图像梯度小于5的图像块删掉\n",
    "\n",
    "### 数据增广\n",
    "- 为保留文字信息的先验性，不进行任何数据增强，只做归一化处理\n",
    "\n",
    "# 五、训练细节\n",
    "- 训练配置\n",
    "总迭代数：450000 iteration\n",
    "我们采用batch size为16来进行训练450000次迭代。\n",
    "我们采用了余弦退火的学习率策略来优化网络，学习率我们采用1e-4，优化器为Adam。\n",
    "- 损失函数为L1Loss\n",
    "\n",
    "# 六、测试细节\n",
    "- 测试图片预先全部输入到二分类模型中，得到包含中文图片路径的list和包含英文图片路径的list\n",
    "- 中文图片路径的list送入到中文模型中，英文图片路径的list送入到英文模型中\n",
    "- 在测试中我们输入到模型中的尺寸为256X256,由于我们将原图裁剪，所以图片边缘的处理尤为重要，我们采用overlap的方法，使图片patches之间的重叠部分为24，这就保证了在图片patcher复位的过程中前一个patch取到重叠区域的一半，也就是12个像素长度，后一个patch从重叠区域的一半开始取，这就保证了patches边缘在复位的时候可以很好的过渡。\n",
    "- 整个测试过程为串行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、代码结构\n",
    "### chinese_code && english_code:\n",
    "- dataloader: 定义数据增强函数和数据集\n",
    "- models: 定义网络模型\n",
    "- utils: 定义评价指标函数和其它函数\n",
    "- checkpoint: 模型训练输出文件夹\n",
    "- result:模型测试输出文件夹\n",
    "- train.py: 训练脚本\n",
    "- *train.txt:预先生成corp的位置信息，这个位置信息通过切分并剔除空白区域后得到的，没有直接生成裁剪好的图片是为了节约内存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、上分策略\n",
    "\n",
    "上分策略主要集中在数据清洗，中英文分开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码启动过程\n",
    "## erasenet训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T01:16:31.851716Z",
     "iopub.status.busy": "2022-09-07T01:16:31.851238Z",
     "iopub.status.idle": "2022-09-07T01:18:25.142057Z",
     "shell.execute_reply": "2022-09-07T01:18:25.140650Z",
     "shell.execute_reply.started": "2022-09-07T01:16:31.851682Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "### 解压数据\n",
    "!cd ./ && unzip -q *.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压完手动把所有的 x,x2,x4的文件里的文件合并，最后得到 x,x2,x4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###裁剪四周空白区域\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from pdb import set_trace as stx\n",
    "\n",
    "def trim(img):\n",
    "        val=230\n",
    "        sp = img.shape  # 获取图像形状：返回【行数值，列数值】列表,sp3为RGB\n",
    "        sz1 = sp[0]\n",
    "        sz2 = sp[1]\n",
    "        n1 = 0\n",
    "        n2 = sz1\n",
    "        n3 = 0\n",
    "        n4 = sz2    #n1~n4代表上下左右的分界线\n",
    "        for i in range(sz1):\n",
    "            for j in range(sz2):\n",
    "                px = np.mean(img[i, j])\n",
    "                if px < val:   #我的图片是灰度图像，如果是彩色的图，可以用255*3以下的值来判定范围\n",
    "                    n1 = i\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        for m in range(sz1 - 1, 0, -1):\n",
    "            for n in range(sz2):\n",
    "                px = np.mean(img[m, n])\n",
    "                if px < val:\n",
    "                    n2 = m\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        for p in range(sz2):\n",
    "            for q in range(sz1):\n",
    "                px = np.mean(img[q, p])\n",
    "                if px < val:\n",
    "                    n3 = p\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        for o in range(sz2 - 1, 0, -1):\n",
    "            for u in range(sz1):\n",
    "                px = np.mean(img[u, o])\n",
    "                if px < val:\n",
    "                    n4 = o\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "      \n",
    "        return max(0,n1-5),min(sz1,n2+5),max(0,n3-5),min(sz2,n4+5)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #原图路径\n",
    "    x_path='./x/'\n",
    "    x2_path='./x2/'\n",
    "    x4_path='./x4/'\n",
    "    #保存路径\n",
    "    nn_x_path='./xx/'\n",
    "    nn_x2_path='./xx2/'\n",
    "    nn_x4_path='/xx4/'\n",
    "\n",
    "    file_names=os.listdir(x_path)\n",
    "    count=0\n",
    "    for name in file_names:\n",
    "        print(count)\n",
    "        x_img_path=os.path.join(x_path,name)\n",
    "        x2_img_path=os.path.join(x2_path,name)\n",
    "        x4_img_path=os.path.join(x4_path,name)\n",
    "\n",
    "        x_img=cv2.imread(x_img_path)\n",
    "        x2_img=cv2.imread(x2_img_path)\n",
    "        x4_img=cv2.imread(x4_img_path)\n",
    "        y1,y2,x1,x2=trim(x_img)\n",
    "        x_img=x_img[y1:y2,x1:x2,:]\n",
    "        x2_img=x2_img[y1*2:y2*2,x1*2:x2*2,:]\n",
    "        x4_img=x4_img[y1*4:y2*4,x1*4:x2*4,:]\n",
    "\n",
    "        cv2.imwrite(x_path+name,x_img)\n",
    "        cv2.imwrite(x2_path+name,x2_img)\n",
    "        cv2.imwrite(x4_path+name,x4_img)\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 xx 文件夹里挑出所有的中文图片，xx2,xx4中对应的文件也剪切出来，得到chinese_x,chinese_x2,chinese_x4\n",
    "同理剩下的英文图片组成 english_x,english_x2,english_x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####生成训练使用的包含corp位置的train.txt,只需要对chinese_x,和english_x生成corp位置，*_x2,*_x4对应的corp坐标分别乘以2和4就是对应label\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "x_path='./chinese_x' \n",
    "file_names=os.listdir(x_path)\n",
    "base=128\n",
    "retreat=64\n",
    "\n",
    "with open (\"c_train.txt\",mode=\"a\") as f:\n",
    "    for name in file_names:\n",
    "        x_img_path=os.path.join(x_path,name)\n",
    "        x_img=cv2.imread(x_img_path)\n",
    "        w_split=[]\n",
    "        h_split=[]\n",
    "        h,w,c=x_img.shape\n",
    "        dynamic_w=0\n",
    "        dynamic_h=0\n",
    "        while(dynamic_w<w):\n",
    "            w_split.append(dynamic_w)\n",
    "            dynamic_w+=base-retreat\n",
    "            if(dynamic_w+base>=w):\n",
    "                dynamic_w=w-base\n",
    "                w_split.append(dynamic_w)\n",
    "                break\n",
    "\n",
    "        while(dynamic_h<h):\n",
    "            h_split.append(dynamic_h)\n",
    "            dynamic_h+=base-retreat\n",
    "\n",
    "            if(dynamic_h+base>=h):\n",
    "                dynamic_h=h-base\n",
    "                h_split.append(dynamic_h)\n",
    "                break\n",
    "    \n",
    "        boundbox=[]\n",
    "        for i in range(len(w_split)):\n",
    "            for j in range(len(h_split)):\n",
    "                if(i==0 and j ==0 ):\n",
    "                    boundbox.append([base*i,base,base*j,base])\n",
    "                elif(i==0):\n",
    "                    boundbox.append([base*i,base,h_split[j],h_split[j]+base])\n",
    "                elif(j==0):\n",
    "                    boundbox.append([w_split[i],w_split[i]+base,base*j,base])\n",
    "                else:\n",
    "                    boundbox.append([w_split[i],w_split[i]+base,h_split[j],h_split[j]+base])\n",
    "        boundbox=np.array(boundbox)\n",
    "    \n",
    "        for i in range(len(boundbox)):\n",
    "            box=boundbox[i]\n",
    "            cur=x_img[box[2]:box[3],box[0]:box[1],:]\n",
    "            sobelx = cv2.Sobel(cur,cv2.CV_64F,1,0,ksize=3)\n",
    "            sobelx = cv2.convertScaleAbs(sobelx)\n",
    "            sobely = cv2.Sobel(cur,cv2.CV_64F,0,1,ksize=3)\n",
    "            sobely = cv2.convertScaleAbs(sobely)\n",
    "            sobelxy = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)\n",
    "            val=np.mean(sobelx)\n",
    "            if(val<4):\n",
    "                continue\n",
    "            f.write(name+' '+str(box[2])+','+str(box[3])+','+str(box[0])+','+str(box[1]))\n",
    "            f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scikit-image in c:\\programdata\\anaconda3\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.6.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (5.0.6)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting warmup_scheduler\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/00/39/f77fb5a7a572891c1f4df1d8e1373a1380cb6d861933886334553244d002/warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "Building wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py): started\n",
      "  Building wheel for warmup-scheduler (setup.py): finished with status 'done'\n",
      "  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2998 sha256=e51155ddd5e11b5b054fc3308df854a41a5ec4e7f4f81ba9f62f2fe38d60363b\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\af\\09\\35\\3ef9059c328587fc37578f2e6b4039b3fbe6485a99ae9fc41e\n",
      "Successfully built warmup-scheduler\n",
      "Installing collected packages: warmup-scheduler\n",
      "Successfully installed warmup-scheduler-0.3\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "## 安装训练所需的python包\n",
    "! pip install torch==1.8.1\n",
    "! pip install torchvision==0.9.1\n",
    "! pip install natsort  \n",
    "! pip install opencv-python\n",
    "! pip install scikit-image\n",
    "! pip install warmup_scheduler\n",
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights into state dict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 24, in <module>\n",
      "    yolo = YOLO()\n",
      "  File \"c:\\Users\\Administrator\\Desktop\\BaiduDiskAI_DocRemoveCover_top3\\erasenet_code\\models\\yolo.py\", line 48, in __init__\n",
      "    self.generate()\n",
      "  File \"c:\\Users\\Administrator\\Desktop\\BaiduDiskAI_DocRemoveCover_top3\\erasenet_code\\models\\yolo.py\", line 77, in generate\n",
      "    self.net = self.net.cuda()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 491, in cuda\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 409, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 491, in <lambda>\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 164, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "## 利用L1Loss训练\n",
    "! cd chinese_model && python train.py \n",
    "! cd english_model && python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "## onnxruntime-gpu 测试脚本 ##\n",
    "    \n",
    "! cd test_code/ && python predict.py {your_test_data_path} {x2_save_path} {x4_save_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
